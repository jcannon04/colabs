{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1QMBbgwPJh+MSpVpz7ca0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcannon04/colabs/blob/main/Byte_Workshop_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ehqe_NViPID"
      },
      "outputs": [],
      "source": [
        "!pip install sqlalchemy langchain langchain-openai\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# import csv for processing\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "  print('Uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=filename, length=len(uploaded[filename])))\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded['MATA_On_Time_Performance_20240216.csv']))\n",
        "engine = create_engine('sqlite:///mata.db')\n",
        "df.to_sql('Mata_Time_Performance', engine, index=False, if_exists='replace')\n",
        "db = SQLDatabase.from_uri(\"sqlite:///mata.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI and Functions Example"
      ],
      "metadata": {
        "id": "w-GYtdBJwKER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "6T0c0X7Vh1Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAhKoiUgoVuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "database_path = \"chinook.db\"\n",
        "\n",
        "def describe_database_schema():\n",
        "    \"\"\"\n",
        "    Retrieves the database schema, including tables and their columns.\n",
        "\n",
        "    Returns:\n",
        "    - Dict: A dictionary with table names as keys and lists of column names as values.\n",
        "    \"\"\"\n",
        "    schema = {}\n",
        "    connection = sqlite3.connect(database_path)\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Retrieve all tables in the database\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "\n",
        "    # Retrieve columns for each table\n",
        "    for table in tables:\n",
        "        table_name = table[0]\n",
        "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "        columns = cursor.fetchall()\n",
        "        schema[table_name] = [column[1] for column in columns]  # column[1] is the name of the column\n",
        "\n",
        "    connection.close()\n",
        "    return json.dumps(schema, indent=4)\n",
        "\n",
        "def execute_sql_query(query):\n",
        "    \"\"\"\n",
        "    Executes an SQL query on the database and returns the results.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The SQL query to execute.\n",
        "\n",
        "    Returns:\n",
        "    - List[Tuple]: The results of the query.\n",
        "    \"\"\"\n",
        "    connection = sqlite3.connect(database_path)\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(query)\n",
        "    results = cursor.fetchall()\n",
        "    connection.close()\n",
        "    return json.dumps(results, indent=4)\n",
        "\n",
        "def execute_function(name, args_dict):\n",
        "    if name == \"execute_sql_query\":\n",
        "        return execute_sql_query(**args_dict)\n",
        "    elif name == \"describe_database_schema\":\n",
        "        return describe_database_schema()\n",
        "    else:\n",
        "        raise ValueError(f\"Function '{name}' not found\")\n",
        "\n",
        "tools = [\n",
        "  {\n",
        "      \"type\": \"function\",\n",
        "      \"function\": {\n",
        "          \"name\": \"execute_sql_query\",\n",
        "          \"description\": \"Executes an SQL query on the predefined database and returns the results. The database path is set within the application code.\",\n",
        "          \"parameters\": {\n",
        "              \"type\": \"object\",\n",
        "              \"properties\": {\n",
        "                  \"query\": {\n",
        "                      \"type\": \"string\",\n",
        "                      \"description\": \"The SQL query to execute.\"\n",
        "                  }\n",
        "              },\n",
        "              \"required\": [\"query\"]\n",
        "          }\n",
        "      }\n",
        "  },\n",
        "  {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"describe_database_schema\",\n",
        "            \"description\": \"Retrieves the database schema, including tables and their columns.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {}\n",
        "            },\n",
        "            \"required\": []\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=userdata.get(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "messages=[\n",
        "  {\"role\": \"system\", \"content\":\n",
        "\n",
        "   \"\"\"You are an SQL assistant built to answer database queries in natural language.\n",
        "      Don't assume column or table names.\n",
        "      Check the schema if unsure\"\"\"\n",
        "  },\n",
        "]\n",
        "\n",
        "def start_chat(tools=None):\n",
        "\n",
        "    while True:\n",
        "        if messages and messages[-1][\"role\"] == 'function':\n",
        "            print(\"Processing function call result...\")\n",
        "        else:\n",
        "            prompt = input(\">> \")\n",
        "            if not prompt:\n",
        "                break\n",
        "            new_message = {\"role\": \"user\", \"content\": prompt}\n",
        "            messages.append(new_message)\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages,\n",
        "            tools=tools\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message\n",
        "\n",
        "        if assistant_message.tool_calls:\n",
        "          tool_calls = assistant_message.tool_calls\n",
        "          for tool_call in tool_calls:\n",
        "            tool = tool_call.function\n",
        "            function_name = tool.name\n",
        "            arguments = json.loads(tool.arguments)\n",
        "            result = execute_function(function_name, arguments)\n",
        "            messages.append({\"role\": \"function\", \"tool_call_id\": tool_call.id, \"name\": tool_call.function.name, \"content\": result})\n",
        "        else:\n",
        "            print(assistant_message.content)\n",
        "            messages.append({\"role\": \"user\", \"content\": assistant_message.content})\n",
        "\n",
        "start_chat(tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "uGejaOWkrifx",
        "outputId": "59ac7b8a-3349-4416-9878-a4174f0f6ef9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> how old is the oldest customer\n",
            "Processing function call result...\n",
            "I'm sorry, but the database does not contain date of birth or age information for customers, so I cannot determine the age of the oldest customer.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-767c8e8b13fc>\u001b[0m in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0massistant_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-767c8e8b13fc>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m(tools)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing function call result...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "def get_schema(_):\n",
        "    return db.get_table_info()\n",
        "\n",
        "def run_query(query):\n",
        "    return db.run(query)\n",
        "\n",
        "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
        "{schema}\n",
        "\n",
        "Question: {question}\n",
        "SQL Query:\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatOpenAI(\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY')\n",
        ")\n",
        "\n",
        "sql_response = (\n",
        "    RunnablePassthrough.assign(schema=get_schema)\n",
        "    | prompt\n",
        "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "G7QwIfOO23Sk"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
        "{schema}\n",
        "\n",
        "Question: {question}\n",
        "SQL Query: {query}\n",
        "SQL Response: {response}\"\"\"\n",
        "\n",
        "prompt_response = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(query=sql_response).assign(\n",
        "        schema=get_schema,\n",
        "        response=lambda x: db.run(x[\"query\"]),\n",
        "    )\n",
        "    | prompt_response\n",
        "    | model\n",
        ")\n",
        "\n",
        "chain.invoke({\"question\": \"list the month and year that the matabus met it's goal\"}).content"
      ],
      "metadata": {
        "id": "yAIlRt03AyVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}